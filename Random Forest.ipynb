{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load NumPy, pandas and time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import copy # for copying dictionaries, standard python library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bins(df,nobins=10,bintype='equal-width'):\n",
    "    cdf=df.copy()\n",
    "    numerical_cdf=df.copy()\n",
    "    for i in ['ID','CLASS']:\n",
    "        if i in cdf: numerical_cdf=numerical_cdf.drop([i], axis=1)\n",
    "    numerical_cdf=numerical_cdf.select_dtypes(include=['number'])\n",
    "    binfunc=[pd.cut,pd.qcut]\n",
    "    binning={}\n",
    "\n",
    "    if bintype==\"equal-width\": a=binfunc[0]\n",
    "    elif bintype==\"equal-size\": a=binfunc[1]\n",
    "    else: a=binfunc[0]\n",
    "\n",
    "    for i in numerical_cdf:\n",
    "        res,bins=a(cdf[i],nobins,retbins=True,labels=False,duplicates='drop')\n",
    "        bins[0]=-np.inf\n",
    "        bins[-1]=np.inf\n",
    "        binning[i]=bins\n",
    "        cdf[i]=res.astype('category')\n",
    "    return cdf,binning\n",
    "\n",
    "def apply_bins(df,binning):\n",
    "    cdf=df.copy()\n",
    "    numerical_cdf=df.copy()\n",
    "    for i in ['ID','CLASS']:\n",
    "        numerical_cdf=numerical_cdf.drop([i], axis=1)\n",
    "    numerical_cdf=numerical_cdf.select_dtypes(include=['number'])\n",
    "\n",
    "    for i in numerical_cdf:\n",
    "        bins=binning[i]\n",
    "        res,bins=pd.cut(cdf[i],bins,retbins=True,labels=False,duplicates='drop')\n",
    "        cdf[i]=res.astype('category')\n",
    "    return cdf\n",
    "\n",
    "\n",
    "def create_imputation(anneal_train_df):\n",
    "    anneal_train_df_copy = anneal_train_df.copy()\n",
    "    imputation_template = {}\n",
    "    \n",
    "    df_cols = anneal_train_df_copy.loc[:, ~anneal_train_df_copy.columns.isin(['ID', 'CLASS'])]\n",
    "    numerical_columns = df_cols.select_dtypes(include=['number']).columns\n",
    "    non_numerical_columns = df_cols.select_dtypes(include=['category', 'object']).columns\n",
    "\n",
    "    anneal_train_df_numerical = anneal_train_df_copy.loc[:, numerical_columns]\n",
    "    for column in anneal_train_df_numerical.columns:\n",
    "        non_missing_col_data = anneal_train_df_numerical.loc[:,column]\n",
    "        if(non_missing_col_data.dropna().shape[0] > 0):\n",
    "            mean_value = non_missing_col_data.mean()\n",
    "        else:\n",
    "            mean_value = 0\n",
    "            \n",
    "        anneal_train_df_copy[column] = anneal_train_df_copy[column].fillna(mean_value)\n",
    "        imputation_template[column] = mean_value\n",
    "\n",
    "    anneal_train_df_categorical = anneal_train_df_copy.loc[:, non_numerical_columns]\n",
    "    for column in anneal_train_df_categorical.columns:\n",
    "        non_missing_col_data = anneal_train_df_categorical[column]\n",
    "        if(non_missing_col_data.dropna().shape[0] > 0):\n",
    "            mode_value = non_missing_col_data.mode()[0]\n",
    "        else:\n",
    "            mode_value = \"\"\n",
    "        \n",
    "        anneal_train_df_copy[column] = anneal_train_df_copy[column].fillna(mode_value)\n",
    "        imputation_template[column] = mode_value\n",
    "            \n",
    "        \n",
    "    return anneal_train_df_copy, imputation_template\n",
    "\n",
    "def apply_imputation(anneal_test_df, imputation):\n",
    "    anneal_test_df_copy = anneal_test_df.copy()\n",
    "    df_cols = anneal_test_df_copy.loc[:, ~anneal_test_df_copy.columns.isin(['ID', 'CLASS'])]\n",
    "    \n",
    "    for column in df_cols.columns:\n",
    "        anneal_test_df_copy[column] = anneal_test_df_copy[column].fillna(imputation[column])\n",
    "\n",
    "    return anneal_test_df_copy\n",
    "\n",
    "\n",
    "def accuracy(pred_df, label):\n",
    "    \n",
    "    score = 0\n",
    "    for row in range(len(pred_df)):\n",
    "        pred_row = pred_df.iloc[row,:]\n",
    "        if pred_row.idxmax() == label[row]:\n",
    "            score = score + 1\n",
    "            \n",
    "    return (score/len(pred_df))\n",
    "\n",
    "\n",
    "def brier_score(df_file, correctlabels):\n",
    "    correctlabels_df = pd.DataFrame(correctlabels)\n",
    "    correctlabels_df = correctlabels_df.astype(pd.api.types.CategoricalDtype(categories= df_file.columns))\n",
    "    correctlabels_hot = pd.get_dummies(correctlabels_df)\n",
    "\n",
    "    score = []\n",
    "    for row in range(np.size(df_file,0)):\n",
    "        for col in range(np.size(df_file,1)):\n",
    "            score_each_element = df_file.iloc[row,col]- correctlabels_hot.iloc[row,col]\n",
    "            score_each_element = np.power(score_each_element, 2)\n",
    "            score.append(score_each_element)\n",
    "\n",
    "    brier_score = sum(score)/np.size(df_file,0)\n",
    "    \n",
    "    return(brier_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Define the class DecisionTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree():\n",
    "    \n",
    "    def __init__(self, class_label = 'CLASS'):\n",
    "        self.class_label = class_label\n",
    "        self.binning = None\n",
    "        self.imputation = None\n",
    "        self.labels = None\n",
    "        self.model = None\n",
    "        \n",
    "    def class_entropy(self, dataframe):\n",
    "        feature = self.class_label\n",
    "        \n",
    "        column = dataframe[feature]\n",
    "        column_len = column.shape[0]\n",
    "        column_values = column.unique()\n",
    "        \n",
    "        def test(col_val):\n",
    "            Pi = column[column == col_val].shape[0]/column_len\n",
    "            return Pi*np.log2(Pi)\n",
    "        \n",
    "        S = - sum([test(col_val) for col_val in column_values])\n",
    "        return S\n",
    "    \n",
    "    def feature_entropy(self, dataframe, feature, feature_val):\n",
    "        column = dataframe[feature]\n",
    "        S_feature_val = self.class_entropy(dataframe[column == feature_val])\n",
    "        \n",
    "        return S_feature_val\n",
    "    \n",
    "    def info_gain(self, dataframe, feature):\n",
    "        S_0 = self.class_entropy(dataframe)\n",
    "        \n",
    "        column = dataframe[feature]\n",
    "        column_len = column.shape[0]\n",
    "\n",
    "        column_values = dataframe[feature].unique()\n",
    "        \n",
    "        def test(col_val):\n",
    "            N_i = column[column == col_val].shape[0]\n",
    "            S_col_val = self.feature_entropy(dataframe, feature, col_val)\n",
    "            return S_col_val * N_i/column_len\n",
    "        \n",
    "        inf_gain = S_0 - sum([test(col_val) for col_val in column_values])\n",
    "        return inf_gain\n",
    "    \n",
    "    \n",
    "    def split_on_feature(self, dataframe, node_dict, feature, min_samples_split):\n",
    "        column = dataframe[feature]\n",
    "        \n",
    "        dataframe_without_col = dataframe.loc[:, ~dataframe.columns.isin([feature])]\n",
    "        \n",
    "        for value in column.unique():\n",
    "            node_dict[value] = dict()\n",
    "            \n",
    "            dataframe_split = dataframe_without_col[column == value]\n",
    "            class_prob = dataframe_split[self.class_label].value_counts() / dataframe_split.shape[0]\n",
    "            node_dict[value]['class_prob'] = class_prob\n",
    "            \n",
    "            if(max(class_prob) == 1):\n",
    "                node_dict[value]['isleaf'] = True\n",
    "\n",
    "            else:\n",
    "                node_dict[value]['isleaf'] = False\n",
    "                self.grow_tree(dataframe_split, node_dict[value], min_samples_split)\n",
    "                \n",
    "        \n",
    "        \n",
    "    def grow_tree(self, dataframe, node_dict, min_samples_split):\n",
    "        \"\"\" Divide and conquer algorithm \"\"\"\n",
    "        \n",
    "        class_prob = dataframe[self.class_label].value_counts() / dataframe.shape[0]\n",
    "        node_dict['class_prob'] = class_prob\n",
    "        \n",
    "        if(dataframe.shape[0] >= min_samples_split):\n",
    "            max_info_gain = -np.inf\n",
    "            max_info_gain_feature = None\n",
    "            for feature in dataframe.columns:\n",
    "                if feature == self.class_label:\n",
    "                    continue\n",
    "                \n",
    "                info_gain = self.info_gain(dataframe, feature)\n",
    "                if info_gain > max_info_gain:\n",
    "                    max_info_gain = info_gain\n",
    "                    max_info_gain_feature = feature\n",
    "\n",
    "            if(max_info_gain_feature != None):\n",
    "                node_dict['feature'] = max_info_gain_feature\n",
    "                node_dict['isleaf'] = False\n",
    "                node_dict = self.split_on_feature(dataframe, node_dict, max_info_gain_feature, min_samples_split)\n",
    "        else:\n",
    "            node_dict['isleaf'] = True\n",
    "            \n",
    "        return node_dict\n",
    "        \n",
    "            \n",
    "        \n",
    "    def fit(self, dataframe, nobins=10, bintype=\"equal-width\", min_samples_split = 5):\n",
    "        \n",
    "        dataframe_discrete, self.binning=create_bins(dataframe,nobins,bintype)\n",
    "        \n",
    "        dataframe_imputation, self.imputation = create_imputation(dataframe_discrete)\n",
    "        \n",
    "        self.labels = dataframe['CLASS'].astype('category').unique()\n",
    "        \n",
    "        feature_cols = dataframe_imputation.loc[:, ~dataframe_imputation.columns.isin(['ID'])]\n",
    "\n",
    "        self.model = dict()\n",
    "        self.grow_tree(feature_cols, self.model, min_samples_split)\n",
    "        \n",
    "        \n",
    "    def propagate_tree(self, root_node, row):\n",
    "        node = root_node\n",
    "        while not node['isleaf']:\n",
    "            if 'feature' in node.keys():\n",
    "                feature = node['feature']\n",
    "            else:\n",
    "                break\n",
    "            \n",
    "            feature_val = row[feature]\n",
    "            if feature_val in node:\n",
    "                node = node[feature_val]\n",
    "            else:\n",
    "                break\n",
    "             \n",
    "        if 'class_prob' in node.keys():\n",
    "            return node['class_prob']\n",
    "        else:\n",
    "            all_class = [class_prob for key, class_prob in node.items() \n",
    "                             if key not in ['isleaf', 'feature']]\n",
    "            \n",
    "            class_prob = pd.sum(pd.concat(all_class, axis=1), axis=1)/len(all_class)\n",
    "        \n",
    "            return class_prob\n",
    "            \n",
    "    \n",
    "    def predict(self, dataframe):\n",
    "        \n",
    "        dataframe_disc = apply_bins(dataframe, self.binning)\n",
    "        dataframe_imp = apply_imputation(dataframe_disc, self.imputation)\n",
    "\n",
    "        feature_cols = dataframe_imp.loc[:, ~dataframe_imp.columns.isin(['ID'])]\n",
    "        \n",
    "        df_predictions = pd.DataFrame(0, index=dataframe_imp.index, columns=self.labels,dtype=float)\n",
    "        for index,row in feature_cols.iterrows():\n",
    "            class_prob = self.propagate_tree(self.model, row)\n",
    "            df_predictions.loc[index] = class_prob\n",
    "        \n",
    "\n",
    "        return df_predictions.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define the class DecisionForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionForest(DecisionTree):\n",
    "    def __init__(self, class_label = 'CLASS'):\n",
    "        self.class_label=class_label\n",
    "        self.binning = None\n",
    "        self.impuation = None\n",
    "        self.labels = None\n",
    "        self.model = None\n",
    "        \n",
    "    def tree_fit(self, tree, dataframe_boot, nobins=10, bintype=\"equal-width\", min_samples_split = 5):\n",
    "        feature_cols = dataframe_boot.loc[:, ~dataframe_boot.columns.isin(['ID'])]\n",
    "\n",
    "        tree.model = dict()\n",
    "        tree.grow_tree(feature_cols, tree.model, min_samples_split)\n",
    "        \n",
    "    def fit(self, dataframe, nobins=10, bintype=\"equal-width\", min_samples_split=5, random_features=2, notrees=10):\n",
    "        \n",
    "        dataframe_discrete, self.binning=create_bins(dataframe,nobins,bintype)\n",
    "        dataframe_imputation,self.imputation = create_imputation(dataframe_discrete)\n",
    "\n",
    "        \n",
    "        self.labels = dataframe['CLASS'].astype('category').unique()\n",
    "        dataframe_features = dataframe_imputation.loc[:, ~dataframe_imputation.columns.isin(['ID','CLASS'])]\n",
    "        \n",
    "        self.model = []\n",
    "        for i in range(notrees):\n",
    "            random_feature_cols = list(np.random.choice(dataframe_features.columns, random_features, replace=False))\n",
    "            \n",
    "            bootstrap_df = dataframe_imputation.loc[:, ['ID']+random_feature_cols+['CLASS']]\n",
    "            \n",
    "            tree_model = DecisionTree()\n",
    "            self.tree_fit(tree_model, bootstrap_df, nobins, bintype, min_samples_split)\n",
    "            self.model.append(tree_model)\n",
    "        \n",
    "    def tree_predict(self, tree, dataframe_disc):\n",
    "        df_predictions = pd.DataFrame(0, index=dataframe_disc.index, columns=self.labels, dtype=float)\n",
    "        for index,row in dataframe_disc.iterrows():\n",
    "            class_prob = tree.propagate_tree(tree.model, row)\n",
    "            df_predictions.loc[index] = class_prob\n",
    "        \n",
    "        return df_predictions.fillna(0)\n",
    "        \n",
    "    def predict(self, dataframe):\n",
    "\n",
    "        dataframe_disc = apply_bins(dataframe, self.binning)\n",
    "        dataframe_imp = apply_imputation(dataframe_disc,self.imputation)\n",
    "        \n",
    "        feature_cols = dataframe_imp.loc[:, ~dataframe_imp.columns.isin(['ID'])]\n",
    "\n",
    "        df_predictions = pd.DataFrame(0, index=dataframe.index, columns=self.labels,dtype=float)\n",
    "        for index,tree in enumerate(self.model):\n",
    "            df_prediction = self.tree_predict(tree, feature_cols)\n",
    "            \n",
    "            df_predictions += df_prediction\n",
    "                \n",
    "        df_predictions = df_predictions/len(self.model)\n",
    "            \n",
    "        return df_predictions.fillna(0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time (1, 1): 0.46 s.\n",
      "Testing time (1, 1): 0.99 s.\n",
      "Training time (1, 2): 1.69 s.\n",
      "Testing time (1, 2): 0.99 s.\n",
      "Training time (1, 5): 9.70 s.\n",
      "Testing time (1, 5): 1.19 s.\n",
      "Training time (2, 1): 0.47 s.\n",
      "Testing time (2, 1): 1.08 s.\n",
      "Training time (2, 2): 2.02 s.\n",
      "Testing time (2, 2): 1.04 s.\n",
      "Training time (2, 5): 9.92 s.\n",
      "Testing time (2, 5): 1.20 s.\n",
      "Training time (5, 1): 0.41 s.\n",
      "Testing time (5, 1): 1.05 s.\n",
      "Training time (5, 2): 2.07 s.\n",
      "Testing time (5, 2): 0.97 s.\n",
      "Training time (5, 5): 6.18 s.\n",
      "Testing time (5, 5): 0.97 s.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Brier score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">1</th>\n",
       "      <th>1</th>\n",
       "      <td>0.644860</td>\n",
       "      <td>0.584572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.663551</td>\n",
       "      <td>0.510137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.700935</td>\n",
       "      <td>0.412483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">2</th>\n",
       "      <th>1</th>\n",
       "      <td>0.588785</td>\n",
       "      <td>0.616990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.700935</td>\n",
       "      <td>0.518253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.672897</td>\n",
       "      <td>0.439244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">5</th>\n",
       "      <th>1</th>\n",
       "      <td>0.532710</td>\n",
       "      <td>0.599499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.644860</td>\n",
       "      <td>0.491858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.644860</td>\n",
       "      <td>0.455518</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Accuracy  Brier score\n",
       "1 1  0.644860     0.584572\n",
       "  2  0.663551     0.510137\n",
       "  5  0.700935     0.412483\n",
       "2 1  0.588785     0.616990\n",
       "  2  0.700935     0.518253\n",
       "  5  0.672897     0.439244\n",
       "5 1  0.532710     0.599499\n",
       "  2  0.644860     0.491858\n",
       "  5  0.644860     0.455518"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glass_train_df = pd.read_csv(\"glass_train.txt\")\n",
    "\n",
    "glass_test_df = pd.read_csv(\"glass_test.txt\")\n",
    "\n",
    "forest_model = DecisionForest()\n",
    "\n",
    "test_labels = glass_test_df[\"CLASS\"]\n",
    "\n",
    "min_samples_split_values = [1,2,5]\n",
    "random_features_values = [1,2,5]\n",
    "\n",
    "parameters = [(min_samples_split,random_features) for min_samples_split in min_samples_split_values \n",
    "              for random_features in random_features_values]\n",
    "\n",
    "results = np.empty((len(parameters),2))\n",
    "\n",
    "for i in range(len(parameters)):\n",
    "    t0 = time.perf_counter()\n",
    "    forest_model.fit(glass_train_df,min_samples_split=parameters[i][0],random_features=parameters[i][1])\n",
    "    print(\"Training time {0}: {1:.2f} s.\".format(parameters[i],time.perf_counter()-t0))\n",
    "    t0 = time.perf_counter()\n",
    "    predictions = forest_model.predict(glass_test_df)\n",
    "    print(\"Testing time {0}: {1:.2f} s.\".format(parameters[i],time.perf_counter()-t0))\n",
    "    results[i] = [accuracy(predictions,test_labels),brier_score(predictions,test_labels)] # Assuming that you have defined auc - remove otherwise\n",
    "\n",
    "results = pd.DataFrame(results,index=pd.MultiIndex.from_product([min_samples_split_values,random_features_values]),\n",
    "                       columns=[\"Accuracy\",\"Brier score\"])\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 0.85\n",
      "Brier score on training set: 0.36\n"
     ]
    }
   ],
   "source": [
    "train_labels = glass_train_df[\"CLASS\"]\n",
    "forest_model.fit(glass_train_df,min_samples_split=1)\n",
    "predictions = forest_model.predict(glass_train_df)\n",
    "print(\"Accuracy on training set: {0:.2f}\".format(accuracy(predictions,train_labels)))\n",
    "print(\"Brier score on training set: {0:.2f}\".format(brier_score(predictions,train_labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comment on assumptions, things that do not work properly, etc."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
